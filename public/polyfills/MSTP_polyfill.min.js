!(function () {
  "use strict";
  const e = () =>
    window.AudioContext &&
    "object" == typeof new AudioContext().audioWorklet &&
    "function" == typeof new AudioContext().audioWorklet.addModule;
  console.log(`AudioWorklet supported: ${e()}`),
    self.MediaStreamTrackProcessor ||
      (self.MediaStreamTrackProcessor = class {
        constructor(t, s, i) {
          console.log("track:", t, "worker:", s),
            "video" == t.kind
              ? (console.log(
                  "using MediaStreamTrackProcessor polyfill, create worker"
                ),
                (this.readable = new ReadableStream({
                  async start(e) {
                    (this.video = document.createElement("video")),
                      (this.video.srcObject = new MediaStream([t])),
                      await Promise.all([
                        this.video.play(),
                        new Promise((e) => (this.video.onloadedmetadata = e)),
                      ]),
                      (this.track = t),
                      (this.canvas = new OffscreenCanvas(
                        this.video.videoWidth,
                        this.video.videoHeight
                      )),
                      (this.ctx = this.canvas.getContext("2d", {
                        desynchronized: !0,
                      })),
                      (this.t1 = performance.now()),
                      console.log(
                        "send frameRate to worker, init frameRate:",
                        t.getSettings().frameRate
                      ),
                      s.postMessage({ frameRate: t.getSettings().frameRate }),
                      document.addEventListener(
                        "visibilitychange",
                        async () => {
                          if (((i = !1), document.hidden))
                            return (
                              console.log(
                                "document hidden, using worker to trigger frame, frameRate:",
                                t.getSettings().frameRate,
                                "init:",
                                i
                              ),
                              new Promise((t) => {
                                s.onmessage = (s) => {
                                  (this.t1 = s.data),
                                    this.ctx.drawImage(this.video, 0, 0),
                                    e.enqueue(
                                      new VideoFrame(this.canvas, {
                                        timestamp: this.t1,
                                      })
                                    ),
                                    t();
                                };
                              })
                            );
                          if (!document.hidden) {
                            for (
                              console.log(
                                "document visible, using requestAnimationFrame to trigger frame, frameRate:",
                                t.getSettings().frameRate,
                                "init:",
                                i
                              );
                              performance.now() - this.t1 <
                              1e3 / t.getSettings().frameRate;

                            )
                              await new Promise((e) =>
                                requestAnimationFrame(e)
                              );
                            (this.t1 = performance.now()),
                              this.ctx.drawImage(this.video, 0, 0),
                              e.enqueue(
                                new VideoFrame(this.canvas, {
                                  timestamp: this.t1,
                                })
                              );
                          }
                        }
                      );
                  },
                  async pull(e) {
                    if (i) {
                      for (
                        ;
                        performance.now() - this.t1 <
                        1e3 / t.getSettings().frameRate;

                      )
                        await new Promise((e) => requestAnimationFrame(e));
                      (this.t1 = performance.now()),
                        this.ctx.drawImage(this.video, 0, 0),
                        e.enqueue(
                          new VideoFrame(this.canvas, { timestamp: this.t1 })
                        );
                    }
                  },
                })))
              : "audio" == t.kind &&
                (console.log("using MediaStreamTrackProcessor polyfill"),
                (this.readable = new ReadableStream({
                  async start(s) {
                    if (
                      ((this.ac = new (window.AudioContext ||
                        window.webkitAudioContext)({ sampleRate: 48e3 })),
                      (this.arrays = []),
                      (this.bufferSize = 0),
                      (this.targetBufferSize = 480),
                      (this.baseTime = 1e3 * performance.now()),
                      (this.totalSamplesProcessed = 0),
                      !e())
                    ) {
                      this.bufferSize = 4096;
                      const i = this.ac.createScriptProcessor(
                        this.bufferSize,
                        1,
                        1
                      );
                      i.onaudioprocess = (e) => {
                        const t = e.inputBuffer.getChannelData(0),
                          s = new Float32Array(t.length);
                        s.set(t), this.arrays.push([[s]]);
                      };
                      const a = this.ac.createMediaStreamSource(
                          new MediaStream([t])
                        ),
                        r = this.ac.createGain();
                      return (
                        (r.gain.value = 0),
                        a.connect(i),
                        i.connect(r),
                        r.connect(this.ac.destination),
                        (this.scriptNode = i),
                        (this.source = a),
                        void (this.gainNode = r)
                      );
                    }
                    try {
                      function o() {
                        class e extends AudioWorkletProcessor {
                          constructor() {
                            super(),
                              (this.buffers = []),
                              (this.currentBuffer = null),
                              (this.currentSize = 0),
                              (this.targetSize = 480);
                          }
                          process(e) {
                            const t = e[0];
                            if (!t || !t[0]) return !0;
                            const s = t[0];
                            this.currentBuffer ||
                              ((this.currentBuffer = new Float32Array(
                                this.targetSize
                              )),
                              (this.currentSize = 0));
                            const i = this.targetSize - this.currentSize,
                              a = Math.min(s.length, i);
                            if (
                              (this.currentBuffer.set(
                                s.slice(0, a),
                                this.currentSize
                              ),
                              (this.currentSize += a),
                              this.currentSize >= this.targetSize &&
                                (this.port.postMessage([[this.currentBuffer]]),
                                (this.currentBuffer = null),
                                a < s.length))
                            ) {
                              const e = s.slice(a);
                              (this.currentBuffer = new Float32Array(
                                this.targetSize
                              )),
                                (this.currentSize = e.length),
                                this.currentBuffer.set(e, 0);
                            }
                            return !0;
                          }
                        }
                        registerProcessor("mstp-shim", e);
                      }
                      const n = `(${o.toString()})()`,
                        c = new Blob([n], { type: "application/javascript" }),
                        h = URL.createObjectURL(c);
                      await this.ac.audioWorklet.addModule(h),
                        (this.node = new AudioWorkletNode(
                          this.ac,
                          "mstp-shim"
                        ));
                      const l = this.ac.createGain();
                      (l.gain.value = 0),
                        this.node.connect(l).connect(this.ac.destination),
                        this.ac
                          .createMediaStreamSource(new MediaStream([t]))
                          .connect(this.node),
                        this.node.port.addEventListener(
                          "message",
                          ({ data: e }) => {
                            e[0][0] && this.arrays.push(e);
                          }
                        ),
                        this.node.port.start();
                    } catch (d) {
                      console.log("AudioWorklet failed", d.message);
                    }
                  },
                  async pull(e) {
                    try {
                      for (; !this.arrays.length; )
                        await new Promise((e) => {
                          const t = () => {
                            this.arrays.length > 0 ? e() : setTimeout(t, 5);
                          };
                          t();
                        });
                      const [t] = this.arrays.shift(),
                        s = t[0],
                        i =
                          this.baseTime +
                          Math.floor(
                            (this.totalSamplesProcessed / this.ac.sampleRate) *
                              1e6
                          ),
                        a = 480;
                      let r;
                      if (s.length !== a) {
                        r = new Float32Array(a);
                        const e = Math.min(s.length, a);
                        for (let t = 0; t < e; t++) r[t] = s[t];
                      } else r = s;
                      (this.totalSamplesProcessed += r.length),
                        e.enqueue(
                          new self.AudioData({
                            format: "f32-planar",
                            sampleRate: this.ac.sampleRate,
                            numberOfFrames: r.length,
                            numberOfChannels: 1,
                            timestamp: i,
                            duration: Math.floor(
                              (r.length / this.ac.sampleRate) * 1e6
                            ),
                            data: r,
                          })
                        );
                    } catch (t) {
                      console.log(`[Safari] Error in pull: ${t.message}`),
                        e.error(t);
                    }
                  },
                  cancel() {
                    this.ac && "closed" !== this.ac.state && this.ac.close(),
                      console.log("ReadableStream cancelled");
                  },
                })));
        }
      });
})();
